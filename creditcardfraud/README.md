# creditcardfraud

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python)
![License](https://img.shields.io/badge/license-MIT-green)
![Build](https://img.shields.io/badge/status-complete-success)
![Dataset](https://img.shields.io/badge/dataset-Kaggle-blue)

DetecÃ§Ã£o de fraudes em transaÃ§Ãµes com cartÃ£o de crÃ©dito utilizando tÃ©cnicas de Machine Learning supervisionado e balanceamento de classes. O projeto foi construÃ­do com foco em avaliaÃ§Ã£o de mÃºltiplos modelos, balanceamento com SMOTE, anÃ¡lise de correlaÃ§Ã£o e padronizaÃ§Ã£o de variÃ¡veis.

---

## Estrutura do Projeto

```bash
creditcardfraud/
â”‚
â”œâ”€â”€ creditcard_fraud/                 # DiretÃ³rio com o dataset original
â”‚   â””â”€â”€ creditcard.csv                # Base de dados de transaÃ§Ãµes
â”‚
â”œâ”€â”€ __pycache__/                      # Cache do Python
â”‚
â”œâ”€â”€ best_model.pkl                    # Modelo treinado e serializado
â”œâ”€â”€ correlation_matrix.png           # Matriz de correlaÃ§Ã£o das variÃ¡veis
â”œâ”€â”€ creditcardfraud.zip              # Arquivo ZIP original do Kaggle
â”œâ”€â”€ metrics.json                      # MÃ©tricas de avaliaÃ§Ã£o final
â”‚
â”œâ”€â”€ download_db.py                   # Script para baixar e extrair o dataset
â”œâ”€â”€ evaluation_model.py              # AvaliaÃ§Ã£o dos modelos de ML
â”œâ”€â”€ utils.py                         # Gerenciador automÃ¡tico de dependÃªncias
â””â”€â”€ README.md                        # Este arquivo

Dataset
O projeto utiliza o dataset de fraude com cartÃ£o de crÃ©dito disponibilizado no Kaggle, contendo transaÃ§Ãµes europeias feitas por cartÃµes em setembro de 2013.

Registros: 284.807

Fraudes: 492 (0.17%)

Atributos: 30 (anÃ´nimos via PCA + Time e Amount)

Target: Class (0 = legÃ­tima, 1 = fraude)

Como Executar
1. Clone o repositÃ³rio
bash
Copiar
Editar
git clone https://github.com/seu-usuario/creditcardfraud.git
cd creditcardfraud
2. Configure sua chave da API do Kaggle
Salve o kaggle.json (chave da API) no diretÃ³rio:

bash
Copiar
Editar
~/.kaggle/kaggle.json
3. Baixe e extraia o dataset
bash
Copiar
Editar
python download_db.py
4. Execute o pipeline de avaliaÃ§Ã£o
bash
Copiar
Editar
python evaluation_model.py
Isso irÃ¡:

Carregar o dataset

Gerar a matriz de correlaÃ§Ã£o

Padronizar variÃ¡veis

Balancear com SMOTE

Avaliar cinco modelos:

Logistic Regression

Random Forest

XGBoost

Naive Bayes

SVM (RBF)

Gerenciamento de DependÃªncias
Este projeto utiliza um gerenciador inteligente de dependÃªncias via utils.py. Pacotes ausentes serÃ£o instalados automaticamente.

VocÃª pode instalar manualmente todos os requisitos com:

bash
Copiar
Editar
pip install -r requirements.txt
Um requirements.txt pode ser gerado a partir do log de dependÃªncias importadas.

Resultados
As mÃ©tricas de desempenho incluem:

ROC AUC

Average Precision

Classification Report

Confusion Matrix

Essas mÃ©tricas sÃ£o salvas no arquivo metrics.json, e um resumo ordenado por ROC AUC Ã© impresso no terminal.

ğŸ“Œ Principais Destaques TÃ©cnicos
ğŸ“ PadronizaÃ§Ã£o de Features (StandardScaler)

ğŸ” AnÃ¡lise de CorrelaÃ§Ã£o (seaborn)

âš–ï¸ Balanceamento com SMOTE (imblearn)

ğŸ” Cross-validation

ğŸ§  ComparaÃ§Ã£o de Modelos Supervisionados

ğŸ“Š VisualizaÃ§Ã£o da Matriz de CorrelaÃ§Ã£o

